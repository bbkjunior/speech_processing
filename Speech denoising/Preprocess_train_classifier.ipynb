{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПРЕПРОЦЕССИНГ ДАННЫХ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import  join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = \"D://test_neurolab//train//clean\"\n",
    "#clean_data_path = \"C://input//neurolab//train//train//clean\"\n",
    "noisy_data_path = \"D://test_neurolab//train//noisy\"\n",
    "#noisy_data_path = \"C://input//neurolab//train//train//noisy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СЧИТЫВАЕМ ДАННЫЕ ИЗ ТРЕНИНГОВОГО СЕТА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "for folder in os.listdir(clean_data_path):\n",
    "    for file in os.listdir(join(clean_data_path, folder)):\n",
    "        data = np.load(join(clean_data_path, folder, file))\n",
    "        clean_data.append(data)\n",
    "        \n",
    "noisy_data = []\n",
    "for folder in os.listdir(noisy_data_path):\n",
    "    for file in os.listdir(join(noisy_data_path, folder)):\n",
    "        data= np.load(join(noisy_data_path, folder, file))\n",
    "        noisy_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДЛЯ УНИФИКАЦИИ РАЗМЕРНОСТИ ДАННЫХ БУДЕМ БРАТЬ ЧАСТИ СПЕКТРОГРАММ ОКНАМИ РАЗМЕРА 80*80 И РАЗВОРАЧИВАТЬ ИХ В ВЕКТОРА\n",
    "\n",
    "ОКНА С НЕПОЛНЫМ КОЛИЧЕСВТОМ ДАННЫХ БУДЕМ ДОПОЛНЯТЬИДЕНИЧНЫМИ ДАННЫМИ МЕТОДОМ np.pad\n",
    "\n",
    "ОКНА, ГДЕ КОЛ-ВО ЗАПОЛНЕННЫХ СТОЛБЦОВ МЕНЬШЕ 30 БУДЕМ ИГНОРИРОВАТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel size (966, 80)\n",
      "current size 0 79\n",
      "(6400,)\n",
      "current size 80 159\n",
      "(6400,)\n",
      "current size 160 239\n",
      "(6400,)\n",
      "current size 240 319\n",
      "(6400,)\n",
      "current size 320 399\n",
      "(6400,)\n",
      "current size 400 479\n",
      "(6400,)\n",
      "current size 480 559\n",
      "(6400,)\n",
      "current size 560 639\n",
      "(6400,)\n",
      "current size 640 719\n",
      "(6400,)\n",
      "current size 720 799\n",
      "(6400,)\n",
      "current size 800 879\n",
      "(6400,)\n",
      "current size 880 959\n",
      "(6400,)\n",
      "not enough real data left 7\n"
     ]
    }
   ],
   "source": [
    "def get_rect_windows(mel, debug = False):\n",
    "    if (debug): print(\"mel size\", mel.shape)\n",
    "    windows = []\n",
    "    for i in range(mel.shape[0]//80 + 1):\n",
    "        if (80*(i+1)-1 < mel.shape[0]):\n",
    "            if (debug): print(\"current size\", 80*i, 80*(i+1)-1)\n",
    "                \n",
    "            ixgrid = np.ix_(range(80*i, 80*(i+1)), range(80))\n",
    "            sample = mel[ixgrid]\n",
    "            sample = sample.flatten()\n",
    "            windows.append(sample)\n",
    "            \n",
    "            if (debug): print(sample.shape)\n",
    "        elif(80 - (80*(i+1)-1 - mel.shape[0]) > 30): \n",
    "            \n",
    "            if (debug): print(\"current size\", 80*i, 80*(i+1)-1)\n",
    "            ixgrid = np.ix_(range(80*i, mel.shape[0]), range(80))\n",
    "            if (debug): print(mel[ixgrid].shape)                \n",
    "            pad_matrix = np.pad(mel[ixgrid], ((0, 80 - mel[ixgrid].shape[0]), (0, 0)), 'reflect')\n",
    "            \n",
    "            pad_matrix = pad_matrix.flatten()  \n",
    "            if (debug): print(pad_matrix.shape) \n",
    "            windows.append(pad_matrix)\n",
    "        else:\n",
    "            if (debug): print(\"not enough real data left\", 80 - (80*(i+1)-1 - mel.shape[0]))\n",
    "    return windows\n",
    "ex_data = clean_data[0]\n",
    "a = get_rect_windows(ex_data, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПОЛЬЗУЯСЬ ЗАДАННОЙ ФУНКЦИЕЙ ФОРМУИРЕМ НОВЫЙ ДАТАСЕТ СОСТОЯЩИЙ ИЗ ПОЛУЧЕННЫХ ВЕКТОРОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_wind = []\n",
    "for mel in clean_data:\n",
    "    new_windows = get_rect_windows(mel)\n",
    "    clean_data_wind.extend(new_windows)\n",
    "    \n",
    "noisy_data_wind = []\n",
    "for mel in noisy_data:\n",
    "    new_windows = get_rect_windows(mel)\n",
    "    noisy_data_wind.extend(new_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФОРМИРУЕМ ИТОГОВЫЙ ТРЕНИНГОВЫЙ ДАТАСЕТ И ЦЕЛЕВУЮ ПЕРЕМЕННУЮ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = clean_data_wind + noisy_data_wind\n",
    "\n",
    "y_train_clean = [0 for _ in range(len(clean_data_wind))]\n",
    "y_train_noisy = [1 for _ in range(len(noisy_data_wind))]\n",
    "y_train = y_train_clean + y_train_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБУЧЕНИЕ МОДЕЛЕЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАПУЩЕНО РАНЕЕ. ЗДЕСЬ ПРОСТО ЗАГРУЖАЕМ ПРЕДОБУЧЕННУЮ МОДЕЛЬ\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = pickle.load(open('logreg.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАПУЩЕНО РАНЕЕ. ЗДЕСЬ ПРОСТО ЗАГРУЖАЕМ ПРЕДОБУЧЕННУЮ МОДЕЛЬ\n",
    "tree_model = DecisionTreeClassifier(max_depth=3)  \n",
    "# Fit a decision tree\n",
    "tree_model = tree_model.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tree_model = pickle.load(open('tree_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАПУЩЕНО РАНЕЕ. ЗДЕСЬ ПРОСТО ЗАГРУЖАЕМ ПРЕДОБУЧЕННУЮ МОДЕЛЬ\n",
    "rf = RandomForestClassifier()  \n",
    "rf_model = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_model = pickle.load(open('rf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОЦЕНКА РЕЗУЛЬТАТОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕАЛИЗУЕМ ФУНКЦИЮ, КОТОРАЯ БУДЕТ ПРИНИМАТЬ НА ВХОД СПЕКТРОГРАММУ, РАЗБИВАТЬ ЕЕ НА ОКНА ПО ТОЙ ЖЕ ЛОГИКЕ, ЧТО И ТРЕНИРОВОЧНЫЕ ДАННЫЕ, ДЕЛАТЬ ОЦЕНКУ ДЛЯ КАЖДОГ ОКНА И ВЫДАВАТЬ ОБЩУЮ ОЦЕНКУ ДЛЯ ВСЕЙ СПЕКТРОГРАММЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mel size (658, 80)\n",
      "current size 0 79\n",
      "[0]\n",
      "current size 80 159\n",
      "[0]\n",
      "current size 160 239\n",
      "[0]\n",
      "current size 240 319\n",
      "[0]\n",
      "current size 320 399\n",
      "[0]\n",
      "current size 400 479\n",
      "[0]\n",
      "current size 480 559\n",
      "[0]\n",
      "current size 560 639\n",
      "[0]\n",
      "not enough real data left 19\n",
      "[array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_by_mel(mel, model,debug = False):\n",
    "    if (debug): print(\"mel size\", mel.shape)\n",
    "    predictions = []\n",
    "    for i in range(mel.shape[0]//80 + 1):\n",
    "        if (80*(i+1)-1 < mel.shape[0]):\n",
    "            if (debug): print(\"current size\", 80*i, 80*(i+1)-1)\n",
    "                \n",
    "            ixgrid = np.ix_(range(80*i, 80*(i+1)), range(80))\n",
    "            sample = mel[ixgrid]\n",
    "            sample = sample.flatten()\n",
    "            \n",
    "            current_prediction = model.predict(sample.reshape(1, -1))\n",
    "            \n",
    "            predictions.append(current_prediction)\n",
    "            \n",
    "            if (debug): print(current_prediction)\n",
    "        elif(80 - (80*(i+1)-1 - mel.shape[0]) > 30): \n",
    "            \n",
    "            if (debug): print(\"current size\", 80*i, 80*(i+1)-1)\n",
    "            ixgrid = np.ix_(range(80*i, mel.shape[0]), range(80))\n",
    "            if (debug): print(mel[ixgrid].shape)                \n",
    "            pad_matrix = np.pad(mel[ixgrid], ((0, 80 - mel[ixgrid].shape[0]), (0, 0)), 'reflect')\n",
    "            pad_matrix = pad_matrix.flatten()  \n",
    "            if (debug): print(pad_matrix.shape) \n",
    "            current_prediction = model.predict(pad_matrix.reshape(1, -1))   \n",
    "            predictions.append(current_prediction)\n",
    "        else:\n",
    "            if (debug): print(\"not enough real data left\", 80 - (80*(i+1)-1 - mel.shape[0]))\n",
    "    av_predictions = np.mean(predictions) \n",
    "    if (debug) : print(predictions)   \n",
    "    if(av_predictions > 0.5):\n",
    "        final_prediction = 1\n",
    "    else:\n",
    "        final_prediction = 0\n",
    "         \n",
    "    return final_prediction\n",
    "ex_data = clean_data[1]\n",
    "predict_by_mel(ex_data, logreg, debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СЧИТЫВАЕМ ВАЛИДАЦИОННЫЕ ДАННЫЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data_path_val = \"C://input//neurolab//val//clean\"\n",
    "clean_data_path_val = \"D://test_neurolab//val//val//clean\"\n",
    "\n",
    "clean_data_val = []\n",
    "for folder in os.listdir(clean_data_path_val):\n",
    "    for file in os.listdir(join(clean_data_path_val, folder)):\n",
    "        data = np.load(join(clean_data_path_val, folder, file))\n",
    "        clean_data_val.append(data)\n",
    "        \n",
    "#noisy_data_path_val = \"C://input//neurolab//val//noisy\"\n",
    "noisy_data_path_val = \"D://test_neurolab//val//val//noisy\"\n",
    "noisy_data_val = []\n",
    "for folder in os.listdir(noisy_data_path_val):\n",
    "    for file in os.listdir(join(noisy_data_path_val, folder)):\n",
    "        data= np.load(join(noisy_data_path_val, folder, file))\n",
    "        noisy_data_val.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = clean_data_val + noisy_data_val\n",
    "y_train_clean_val = [0 for _ in range(len(clean_data_val))]\n",
    "y_train_noisy_val = [1 for _ in range(len(noisy_data_val))]\n",
    "y_test = y_train_clean_val + y_train_noisy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оцениваем Логрегрессию\n",
    "predicted = []\n",
    "for ind in range(len(x_test)):\n",
    "    pred = predict_by_mel(x_test[ind], logreg)\n",
    "    predicted.append(pred)\n",
    "    \n",
    "logit_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "logit_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "logit_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "logit_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "logit_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "logit_f1 = metrics.f1_score(y_test, predicted, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оцениваем ДЕРЕВО РЕШЕНИЙ\n",
    "predicted = []\n",
    "for ind in range(len(x_test)):\n",
    "    pred = predict_by_mel(x_test[ind], tree_model)\n",
    "    predicted.append(pred)\n",
    "    \n",
    "tree_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "tree_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "tree_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "tree_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "tree_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "tree_f1 = metrics.f1_score(y_test, predicted, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оцениваем СЛУЧАЙНЫЙ ЛЕС\n",
    "predicted = []\n",
    "for ind in range(len(x_test)):\n",
    "    pred = predict_by_mel(x_test[ind], rf_model)\n",
    "    predicted.append(pred)\n",
    "    \n",
    "rf_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "rf_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "rf_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "rf_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "rf_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "rf_f1 = metrics.f1_score(y_test, predicted, pos_label=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ДЕЛАЕМ ВЫВОДЫ О ПОЛУЧЕННОЙ ТОЧНОСТИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.92700</td>\n",
       "      <td>0.921800</td>\n",
       "      <td>r.f.</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.87700</td>\n",
       "      <td>0.864463</td>\n",
       "      <td>d.Tree</td>\n",
       "      <td>0.962577</td>\n",
       "      <td>0.7845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90125</td>\n",
       "      <td>0.900126</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.910486</td>\n",
       "      <td>0.8900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy        F1     Model  Precision  recall\n",
       "2   0.92700  0.921800      r.f.   0.992503  0.8605\n",
       "1   0.87700  0.864463    d.Tree   0.962577  0.7845\n",
       "0   0.90125  0.900126  Logistic   0.910486  0.8900"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({  \n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.'],\n",
    "  'Accuracy' : [logit_accuracy, tree_accuracy, rf_accuracy],\n",
    "  'Precision': [logit_precision, tree_precision, rf_precision],\n",
    "  'recall' : [logit_recall, tree_recall, rf_recall],\n",
    "  'F1' : [logit_f1, tree_f1, rf_f1]\n",
    "  #'cv_precision' : [logit_cv_mean, tree_cv_mean, rf_cv_mean, svm_cv_mean, knn_cv_mean, bayes_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='Precision', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВЫВОД"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "По заданной метрике Accuracy лучшую производительность продемнстрировал RandomForestClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
