# speech_processing
Передо мной стояли две задачи 
1) классифицировать аудиодорожки на зашумленные и незашулменные 
2) очистить дороки от шума

1)(уровень Junior) Классификация: необходимо реализовать алгоритм, позволяющий
определить, является ли аудиозапись зашумленной или нет.

В данном задании решается стандартная задача классификации, но есть одно затруднение, заключающееся в том, что каждая спектрограмма имеет различную длину.
Чтобы унифицировать данные, подаваемые на обучение модели я решил пройтись по каждой спектрограмме окном размером 80*80 ( решение о размерности было обосновано тем что количество строк равнялось 80 на всех спектрограммах, а количество столбцов всегда превосходило это значение на несколько порядков) и сформировать из полученных результатов новый датафрейм, включающий в себя полученные матрицы 80*80 развернутые в вектор из 6400 элементов и соответствующие им значения (0 - чистая спектрограмма, 1 - зашумленная). Те окна, которые попадали на участки, где данных не хватало дополнялись зеркальными значениями с помощью  np.pad. В том случае если окно попадало на данные, где было меньше 30 столбцов реальных данных,окно не записывалось (я предположил, что это может повредить реальным данным. Как предполагаемое улучшение, можно реализовать модель, которая могла бы предсказывать следующие n миллисекунд спектрограммы на основе предыдущих m миллисекунд, чтобы избежать подобных проблем)

С полученным датафреймом я обучил логистическую регрессию, дерево решений и случайный лес.

Для анализа качества полученных моделей была реализована функция predict_by_mel, которая принимает на вход спектрограмму, разбивает ее на такие же окна размером 80*0, также дополняет окна, где данных больше 30 столбцов, а остальные данные игнорирует. Внутри каждой спектрограммы к каждому полученному окну применялся метод  predict от обученной модели. Под конец вычислений для каждой спектрограммы получался лист предсказаний. Для получения итогового предсказания вычислялось его среднее. Если его значение было больше 0,5, то спектрограмма признавалась зашумленной

По итогам сравнения лучшую accuracy продемонстрировал случайный лес. Таблицу со всеми основными параметрами я вывел в ноутбуке

На валидационных данных, кончено, нужно не только проверять точность но еще и тюнинговать гиперпараметры моделей для более честного сравнения. В качестве примера тюнинга можно привести кросс валидацию. В данном случае я не делал этого, потому что все вычисления у меня длились очень долго. Видимо мощностей моего ПК недостаточно для  полноценного обучения моделей.

Ноутбук с ходом препроцессинга данных, обучения моделей и проверки точности здесь
https://github.com/bbkjunior/speech_processing/blob/master/Speech%20denoising/Preprocess_train_classifier.ipynb

В той же папке лежит скрипт, которому можно подавать или один npy файл со спектрограммой или директорию, где будут лежать папки со спектрограммами (так же как в случае тренинговых и валидационных данных). В первом случае если мы вызовем скрипт с флагом -p то нам выдастся результат обработки одной спектрограммы. Во втором случае скрипт пройдется по всем папкам, соберет все спектрограммы, проанализирует их и запишет полученные предсказания в файл predicted_values.csv
https://github.com/bbkjunior/speech_processing/blob/master/Speech%20denoising/predict_noise.py

2) (уровень Middle) Denoising:

Здесь я руководствовался следующей статьей
http://cs231n.stanford.edu/reports/2015/pdfs/Final_Report_mkayser_vzhong.pdf

В ней был описан препроцессинг значений спектрограммы, который, насколько я понял, уже был осуществлен, так как в ноутбуке, который был предоставлен для ознакомления был произведен np.log, что соответствует описаниям требуемого препроцессинга в статье. Ранжир данных полученный после этой операции в примере очень похож на ранжир данных в треинговом и валидационном сетах, поэтому я сделал вывод, что описанный в статье препроцессинг не требуется.
Далее я обучил MLPRegressor с параметрами, указанными в статье. Процесс обучения можно увидеть в ноутбуке https://github.com/bbkjunior/speech_processing/blob/master/Speech%20denoising/Denoise_train.ipynb

Далее я попытался оценить точность данных, но predict вернул значения nan. Судя по анализу ошибки что-то не так либо с данными, поданными на обучение модели либо с обученными весами. Стоит попробовать поэкспериментировать с разными параметрами обучения модели, типа learning_rate max_iter
Ноутбук, в котором я столкнулся с проблемой здесь
https://github.com/bbkjunior/speech_processing/blob/master/Speech%20denoising/Denoise_validate.ipynb
